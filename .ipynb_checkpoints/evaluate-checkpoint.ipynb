{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q7PvvgOxNyZt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from functools import partial\n",
    "import nltk\n",
    "import requests\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "#from IPython.html import widgets\n",
    "from collections import namedtuple\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, LsiModel, Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import downloader as g_downloader\n",
    "import itertools\n",
    "\n",
    "# gensim uses logging, so set it up \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ctsu83FoNyZu"
   },
   "outputs": [],
   "source": [
    "def download_dataset():\n",
    "    folder_path = os.environ.get(\"IR1_DATA_PATH\")\n",
    "    if not folder_path:\n",
    "        folder_path = \"./datasets/\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    file_location = os.path.join(folder_path, \"cacm.zip\")\n",
    "    \n",
    "    # download file if it doesn't exist\n",
    "    if not os.path.exists(file_location):\n",
    "        \n",
    "        url = \"https://surfdrive.surf.nl/files/index.php/s/M0FGJpX2p8wDwxR/download\"\n",
    "\n",
    "        with open(file_location, \"wb\") as handle:\n",
    "            print(f\"Downloading file from {url} to {file_location}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            for data in tqdm(response.iter_content()):\n",
    "                handle.write(data)\n",
    "            print(\"Finished downloading file\")\n",
    "    \n",
    "    if not os.path.exists(os.path.join(folder_path, \"train.txt\")):\n",
    "        \n",
    "        # unzip file\n",
    "        with zipfile.ZipFile(file_location, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder_path)\n",
    "        \n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TPLms_FqNyZw"
   },
   "outputs": [],
   "source": [
    "def read_cacm_docs(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM documents. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Returns: A list of 2-tuples: (doc_id, document), where 'document' is a single string created by \n",
    "            appending the title and abstract (separated by a \"\\n\"). \n",
    "            In case the record doesn't have an abstract, the document is composed only by the title\n",
    "    \"\"\"\n",
    "\n",
    "    file_dir = root_folder + \"cacm.all\"\n",
    "    keeping = False\n",
    "    temp = \"\"\n",
    "    doc_list =[]\n",
    "\n",
    "    with open(file_dir) as cacm_file:\n",
    "        for line in cacm_file:\n",
    "            line_begin = line[0:2]\n",
    "\n",
    "            if line_begin == \".I\":\n",
    "                doc_index = line.split(\" \")[1].replace(\"\\n\",\"\")\n",
    "                temp = \"\"\n",
    "\n",
    "            elif line_begin == \".T\":\n",
    "                keeping = True\n",
    "\n",
    "            elif line_begin == \".W\":\n",
    "                keeping = True\n",
    "                temp += \"\\n \"\n",
    "\n",
    "            elif line_begin in ['.B', '.A', '.N', '.K']:\n",
    "                keeping = False\n",
    "\n",
    "            elif (line_begin not in ['.I', '.T', '.W', '.B', '.A', '.N', '.X', '.K']):\n",
    "                if keeping:\n",
    "                    temp += line\n",
    "            else:\n",
    "                doc_list.append((doc_index, temp))\n",
    "                keeping = False\n",
    "\n",
    "    return doc_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HehAkHVFNyZw"
   },
   "outputs": [],
   "source": [
    "def read_queries(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads in the CACM queries. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Returns: A list of 2-tuples: (query_id, query)\n",
    "    \"\"\"\n",
    "    \n",
    "    file_dir = root_folder + \"query.text\"\n",
    "    keeping = False\n",
    "    temp = \"\"\n",
    "    query_list =[]\n",
    "\n",
    "    with open(file_dir, \"r\") as query_file:\n",
    "        for line in query_file:\n",
    "            line_begin = line[0:2]\n",
    "\n",
    "            if line_begin == \".I\":\n",
    "                doc_index = line.split(\" \")[1].replace(\"\\n\",\"\")\n",
    "                temp = \"\"\n",
    "\n",
    "            elif line_begin == \".W\":\n",
    "                keeping = True   \n",
    "\n",
    "            elif line_begin == \".A\":\n",
    "                keeping = False\n",
    "\n",
    "            elif (line_begin not in ['.I', '.T', '.W', '.B', '.A', '.N', '.X', '.K']):\n",
    "                if keeping:\n",
    "                    temp += line\n",
    "            else:\n",
    "                query_list.append((doc_index, temp))\n",
    "                keeping = False\n",
    "                \n",
    "    return query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NmTFHQ0nNyZy"
   },
   "outputs": [],
   "source": [
    "def load_stopwords(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Loads the stopwords. The dataset is assumed to be in the folder \"./datasets/\" by default\n",
    "        Output: A set of stopwords\n",
    "    \"\"\"\n",
    "    file_dir = root_folder + \"common_words\"\n",
    "\n",
    "    with open(file_dir , 'r') as f:\n",
    "        stopwords = [line.strip() for line in f]\n",
    "        \n",
    "    return set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "P6D4UbG6NyZy"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "        Tokenizes the input text. Use the WordPunctTokenizer\n",
    "        Input: text - a string\n",
    "        Output: a list of tokens\n",
    "    \"\"\"\n",
    "    tokenized = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    return tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aDdJ3Y57NyZz"
   },
   "outputs": [],
   "source": [
    "def stem_token(token):\n",
    "    \"\"\"\n",
    "        Stems the given token using the PorterStemmer from the nltk library\n",
    "        Input: a single token\n",
    "        Output: the stem of the token\n",
    "    \"\"\"\n",
    "    ps = nltk.stem.PorterStemmer() \n",
    "    return ps.stem(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PyajR9VuNyZz"
   },
   "outputs": [],
   "source": [
    "def process_text(text, stem=False, remove_stopwords=False, lowercase_text=False):\n",
    "    \n",
    "    tokens = []\n",
    "    for token in tokenize(text):\n",
    "        if remove_stopwords and token.lower() in stopwords:\n",
    "            continue\n",
    "        if stem:\n",
    "            token = stem_token(token)\n",
    "        if lowercase_text:\n",
    "            token = token.lower()\n",
    "        tokens.append(token)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YeRr6RUMNyZ0"
   },
   "outputs": [],
   "source": [
    "# In this configuration:\n",
    "# Don't preprocess the text, except to tokenize \n",
    "config_1 = {\n",
    "  \"stem\": False,\n",
    "  \"remove_stopwords\" : False,\n",
    "  \"lowercase_text\": True\n",
    "} \n",
    "\n",
    "\n",
    "# In this configuration:\n",
    "# Preprocess the text, stem and remove stopwords\n",
    "config_2 = {\n",
    "  \"stem\": True,\n",
    "  \"remove_stopwords\" : True,\n",
    "  \"lowercase_text\": True, \n",
    "} \n",
    "\n",
    "####\n",
    "doc_repr_1 = []\n",
    "doc_repr_2 = []\n",
    "for (doc_id, document) in docs:\n",
    "    doc_repr_1.append((doc_id, process_text(document, **config_1)))\n",
    "    doc_repr_2.append((doc_id, process_text(document, **config_2)))\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XtqI2gQaNyZ0"
   },
   "outputs": [],
   "source": [
    "def build_tf_index(documents):\n",
    "    \"\"\"\n",
    "        Build an inverted index (with counts). The output is a dictionary which takes in a token\n",
    "        and returns a list of (doc_id, count) where 'count' is the count of the 'token' in 'doc_id'\n",
    "        Input: a list of documents - (doc_id, tokens) \n",
    "        Output: An inverted index. [token] -> [(doc_id, token_count)]\n",
    "    \"\"\"\n",
    "    tf_index = {}\n",
    "\n",
    "    for doc in documents:\n",
    "        for token in np.unique(doc[1]):\n",
    "            doc_list = (doc[0], doc[1].count(token))\n",
    "\n",
    "            if token in tf_index.keys():\n",
    "                tf_index[token].append(doc_list)\n",
    "            else:\n",
    "                tf_index[token] = [doc_list]\n",
    "    \n",
    "    return tf_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fps12HX9NyZ0"
   },
   "outputs": [],
   "source": [
    "#### Indexed documents based on the two configs\n",
    "\n",
    "# Create the 2 indices\n",
    "tf_index_1 = build_tf_index(doc_repr_1)\n",
    "tf_index_2 = build_tf_index(doc_repr_2)\n",
    "\n",
    "# This function returns the tf_index of the corresponding config\n",
    "def get_index(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: tf_index_1,\n",
    "        2: tf_index_2\n",
    "    }[index_set]\n",
    "\n",
    "####\n",
    "#### Preprocessed query based on the two configs\n",
    "\n",
    "# This function preprocesses the text given the index set, according to the specified config\n",
    "def preprocess_query(text, index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    if index_set == 1:\n",
    "        return process_text(text, **config_1)\n",
    "    elif index_set == 2:\n",
    "        return process_text(text, **config_2)\n",
    "\n",
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "i6o1qWVENyZ1"
   },
   "outputs": [],
   "source": [
    "def bow_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query. \n",
    "        Note: You have to use the `get_index` function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    index = get_index(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    \n",
    "    bag_dict = {}\n",
    "    for q in processed_query:\n",
    "\n",
    "        if q not in index:\n",
    "            continue \n",
    "\n",
    "        for doc_id, tf in index[q]:        \n",
    "            if doc_id not in bag_dict:\n",
    "                    bag_dict[doc_id] = 0.0\n",
    "            \n",
    "            bag_dict[doc_id] += 1.0 \n",
    "\n",
    "    sorted_result = sorted(bag_dict.items(), key=lambda tup: tup[1], reverse = True)\n",
    "\n",
    "    return sorted_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "42e_gaIFNyZ2"
   },
   "outputs": [],
   "source": [
    "def compute_df(documents):\n",
    "    \"\"\"\n",
    "        Compute the document frequency of all terms in the vocabulary\n",
    "        Input: A list of documents\n",
    "        Output: A dictionary with {token: document frequency)\n",
    "    \"\"\"\n",
    "    doc_freq = {}\n",
    "    \n",
    "    for i in range(len(documents)):\n",
    "        tokens = documents[i]\n",
    "        for token in tokens:\n",
    "            if token not in doc_freq:\n",
    "                doc_freq[token] = {i}\n",
    "          \n",
    "            else:\n",
    "                doc_freq[token].add(i)\n",
    "\n",
    "    for token in doc_freq:\n",
    "        doc_freq[token] = len(doc_freq[token])\n",
    "\n",
    "    return doc_freq\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WY4YzoZNNyZ2"
   },
   "outputs": [],
   "source": [
    "#### Compute df based on the two configs\n",
    "\n",
    "# get the document frequencies of each document\n",
    "df_1 = compute_df([d[1] for d in doc_repr_1])\n",
    "df_2 = compute_df([d[1] for d in doc_repr_2])\n",
    "\n",
    "def get_df(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: df_1,\n",
    "        2: df_2\n",
    "    }[index_set]\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Tjt36QvlNyZ3"
   },
   "outputs": [],
   "source": [
    "def tfidf_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using tf-idf. \n",
    "        Note #1: You have to use the `get_index` (and the `get_df`) function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    \n",
    "    n_doc = len(doc_repr_1) if index_set == 1 else len(doc_repr_2)\n",
    "\n",
    "    tfidf_dict = {}\n",
    "\n",
    "    for q in processed_query:\n",
    "\n",
    "        if q not in index:\n",
    "            continue \n",
    "\n",
    "        for doc_id, tf in index[q]:        \n",
    "            if doc_id not in tfidf_dict:\n",
    "                    tfidf_dict[doc_id] = 0\n",
    "            \n",
    "            tfidf_dict[doc_id] += tf*np.log(n_doc/df[q])\n",
    "\n",
    "    sorted_result = sorted(tfidf_dict.items(), key=lambda tup: tup[1], reverse = True)\n",
    "\n",
    "    return sorted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "roRYISlkNyZ3"
   },
   "outputs": [],
   "source": [
    "#### Document length for normalization\n",
    "\n",
    "def doc_lengths(documents):\n",
    "    doc_lengths = {doc_id:len(doc) for (doc_id, doc) in documents}\n",
    "    return doc_lengths\n",
    "\n",
    "doc_lengths_1 = doc_lengths(doc_repr_1)\n",
    "doc_lengths_2 = doc_lengths(doc_repr_2)\n",
    "\n",
    "def get_doc_lengths(index_set):\n",
    "    assert index_set in {1, 2}\n",
    "    return {\n",
    "        1: doc_lengths_1,\n",
    "        2: doc_lengths_2\n",
    "    }[index_set]\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "KaNDnMLPNyZ4"
   },
   "outputs": [],
   "source": [
    "def naive_ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using a naive QL model. \n",
    "        Note #1: You have to use the `get_index` (and get_doc_lengths) function created in the previous cells\n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    unigram_probs = {}\n",
    "\n",
    "\n",
    "    for i, q in enumerate(processed_query):\n",
    "      if q not in index:\n",
    "        continue\n",
    "      \n",
    "      if i > 0:\n",
    "        tf_dicts = dict(index[q])\n",
    "        for doc_id in unigram_probs:\n",
    "          if doc_id in tf_dicts:\n",
    "            unigram_probs[doc_id] *= 1.0 * tf_dicts[doc_id] / doc_lengths[doc_id]  \n",
    "        \n",
    "          else:\n",
    "            unigram_probs[doc_id] = 0\n",
    "\n",
    "      else:    \n",
    "        for doc_id, tf in index[processed_query[0]]:\n",
    "          unigram_probs[doc_id] = tf / doc_lengths[doc_id] \n",
    "\n",
    "    sorted_rank = sorted(unigram_probs.items(), key = lambda d: d[1], reverse = True)\n",
    "    \n",
    "    return sorted_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "I34arRELNyZ4"
   },
   "outputs": [],
   "source": [
    "def get_doc_ids(query, index_set):\n",
    "  \"return doc_id list of documents that contain the query terms\"\n",
    "  index = get_index(index_set)\n",
    "  doc_ids = []\n",
    "  for q in query:\n",
    "    if q not in index:\n",
    "      continue\n",
    "      \n",
    "    for doc_id, _ in index[q]:\n",
    "      if doc_id not in doc_ids:\n",
    "        doc_ids.append(doc_id)\n",
    "    \n",
    "  return doc_ids\n",
    "\n",
    "\n",
    "def ql_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using a QL model \n",
    "        with Jelinek-Mercer Smoothing (set smoothing=0.1). \n",
    "        \n",
    "        \n",
    "        Note #1: You have to use the `get_index` (and get_doc_lengths) function created in the previous cells\n",
    "        Note #2: You might have to create some variables beforehand and use them in this function\n",
    "        \n",
    "        \n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    index = get_index(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    \n",
    "    doc_ids = get_doc_ids(processed_query, index_set)\n",
    "    cl = sum(doc_lengths.values())\n",
    "    lamb = 0.1\n",
    "    unigram_probs = dict(zip(doc_ids, np.zeros(len(doc_ids))))\n",
    "    \n",
    "    for i, q in enumerate(processed_query):\n",
    "      if q not in index:\n",
    "        continue\n",
    "      \n",
    "      tf_dict = dict(index[q])\n",
    "      cf = sum(tf_dict.values())\n",
    "\n",
    "      for doc_id in doc_ids:\n",
    "        tf = tf_dict[doc_id] if doc_id in tf_dict else 0\n",
    "        unigram_probs[doc_id] += np.log((1 - lamb) * tf / doc_lengths[doc_id] + lamb * cf / cl)\n",
    "          \n",
    "    sorted_rank = sorted(unigram_probs.items(), key = lambda d: d[1], reverse = True)\n",
    "    return sorted_rank\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "u0j_qGA1NyZ5"
   },
   "outputs": [],
   "source": [
    "def bm25_search(query, index_set):\n",
    "    \"\"\"\n",
    "        Perform a search over all documents with the given query using BM25. Use k_1 = 1.5 and b = 0.75\n",
    "        Note #1: You have to use the `get_index` (and `get_doc_lengths`) function created in the previous cells\n",
    "        Note #2: You might have to create some variables beforehand and use them in this function\n",
    "        \n",
    "        Input: \n",
    "            query - a (unprocessed) query\n",
    "            index_set - the index to use\n",
    "        Output: a list of (document_id, score), sorted in descending relevance to the given query \n",
    "    \"\"\"\n",
    "    \n",
    "    index = get_index(index_set)\n",
    "    df = get_df(index_set)\n",
    "    doc_lengths = get_doc_lengths(index_set)\n",
    "    processed_query = preprocess_query(query, index_set)\n",
    "    \n",
    "    k_1, b = 1.5, 0.75\n",
    "    bm25_dict = {}\n",
    "    dl_avg = 1.0 * sum(doc_lengths.values()) / len(doc_lengths)\n",
    " \n",
    "    for q in processed_query:\n",
    "      if q not in index:\n",
    "        continue\n",
    "      \n",
    "      for doc_id, tf in index[q]:\n",
    "        if doc_id not in bm25_dict:\n",
    "          bm25_dict[doc_id] = 0\n",
    "        \n",
    "        idf = np.log(len(doc_lengths)/df[q])\n",
    "        bm25_dict[doc_id] += idf * (k_1 + 1) * tf / (k_1 * (1-b + b * doc_lengths[doc_id]/ dl_avg) + tf)\n",
    "    \n",
    "    sorted_rank = sorted(bm25_dict.items(), key = lambda d: d[1], reverse = True)\n",
    "    return sorted_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "yPeZ8e4yNyZ6"
   },
   "outputs": [],
   "source": [
    "#### Highlighter function\n",
    "# class for results\n",
    "ResultRow = namedtuple(\"ResultRow\", [\"doc_id\", \"snippet\", \"score\"])\n",
    "docs_by_id = dict((d[0], d[1]) for d in docs)\n",
    "\n",
    "def highlight_text(document, query, tol=17):\n",
    "    import re\n",
    "    tokens = tokenize(query)\n",
    "    regex = \"|\".join(f\"(\\\\b{t}\\\\b)\" for t in tokens)\n",
    "    regex = re.compile(regex, flags=re.IGNORECASE)\n",
    "    output = \"\"\n",
    "    i = 0\n",
    "    for m in regex.finditer(document):\n",
    "        start_idx = max(0, m.start() - tol)\n",
    "        end_idx = min(len(document), m.end() + tol)\n",
    "        output += \"\".join([\"...\",\n",
    "                        document[start_idx:m.start()],\n",
    "                        \"<strong>\",\n",
    "                        document[m.start():m.end()],\n",
    "                        \"</strong>\",\n",
    "                        document[m.end():end_idx],\n",
    "                        \"...\"])\n",
    "    return output.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "def make_results(query, search_fn, index_set):\n",
    "    results = []\n",
    "    for doc_id, score in search_fn(query, index_set):\n",
    "        highlight = highlight_text(docs_by_id[doc_id], query)\n",
    "        if len(highlight.strip()) == 0:\n",
    "            highlight = docs_by_id[doc_id]\n",
    "        results.append(ResultRow(doc_id, highlight, score))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50,
     "referenced_widgets": [
      "01458fb095424240baee28c6b347555c",
      "ac7ec29c04f64e2f962476650c3c4e68",
      "33dc764cdf144f79bd8d3ef202ff79bd"
     ]
    },
    "id": "SN9U7xe8NyZ6",
    "outputId": "2eebffe8-2945-4adc-d4d4-7b2193207977"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a0558c0d084beab97339b7a9630f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Search Bar')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_fn = bm25_search\n",
    "index_set = 1\n",
    "\n",
    "text = widgets.Text(description=\"Search Bar\", width=200)\n",
    "display(text)\n",
    "\n",
    "def handle_submit(sender):\n",
    "    print(f\"Searching for: '{sender.value}'\")\n",
    "    \n",
    "    results = make_results(sender.value, search_fn, index_set)\n",
    "    \n",
    "    # display only the top 5\n",
    "    results = results[:5]\n",
    "    \n",
    "    body = \"\"\n",
    "    for idx, r in enumerate(results):\n",
    "        body += f\"<li>Document #{r.doc_id}({r.score}): {r.snippet}</li>\"\n",
    "    display(HTML(f\"<ul>{body}</ul>\"))\n",
    "    \n",
    "\n",
    "text.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "Dbo0p7VINyZ7"
   },
   "outputs": [],
   "source": [
    "def read_qrels(root_folder = \"./datasets/\"):\n",
    "    \"\"\"\n",
    "        Reads the qrels.text file. \n",
    "        Output: A dictionary: query_id -> [list of relevant documents]\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    query_f = open(os.path.join(root_folder, \"qrels.text\"), 'r')\n",
    "    query_dic = {}\n",
    "\n",
    "    for line in query_f:\n",
    "      q_id, doc_id, _, _ = line.split()\n",
    "      \n",
    "      # make queries and qrels consistent in query_id ('01'->'1')\n",
    "      q_id = str(int(q_id))\n",
    "      \n",
    "      if q_id not in query_dic:\n",
    "        query_dic[q_id] = []\n",
    "      query_dic[q_id].append(doc_id)\n",
    "    \n",
    "    return query_dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "nnlKssKdNyZ7"
   },
   "outputs": [],
   "source": [
    "def precision_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "        Compute Precision@K\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), \n",
    "                    with the most relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "            k: the cut-off\n",
    "        Output: Precision@K\n",
    "    \"\"\"\n",
    "    relevant_cnt = 0\n",
    "\n",
    "    for i, (doc_id, _) in enumerate(results):\n",
    "      if doc_id in relevant_docs:\n",
    "        relevant_cnt += 1\n",
    "      if i == k - 1:\n",
    "        break\n",
    "\n",
    "    return relevant_cnt / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "OTbYzC-WNyZ8"
   },
   "outputs": [],
   "source": [
    "def recall_k(results, relevant_docs, k):\n",
    "    \"\"\"\n",
    "        Compute Recall@K\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "            k: the cut-off\n",
    "        Output: Recall@K\n",
    "    \"\"\"\n",
    "    relevant_cnt = 0\n",
    "\n",
    "    for i, (doc_id, _) in enumerate(results):\n",
    "      if doc_id in relevant_docs:\n",
    "        relevant_cnt += 1\n",
    "      if i == k - 1:\n",
    "        break\n",
    "\n",
    "    return relevant_cnt / len(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "wXBvfQ0QNyZ8"
   },
   "outputs": [],
   "source": [
    "def average_precision(results, relevant_docs):\n",
    "    \"\"\"\n",
    "        Compute Average Precision (for a single query - the results are \n",
    "        averaged across queries to get MAP in the next few cells)\n",
    "        Hint: You can use the recall_k and precision_k functions here!\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most \n",
    "                    relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "        Output: Average Precision\n",
    "    \"\"\"\n",
    "    relevant_cnt = 0\n",
    "    sum = 0\n",
    "    search_cnt = 0\n",
    "\n",
    "    while relevant_cnt < len(relevant_docs) and search_cnt < len(results):\n",
    "      doc_id, _ = results[search_cnt]\n",
    "      search_cnt += 1\n",
    "      if doc_id in relevant_docs:\n",
    "        relevant_cnt += 1\n",
    "        sum += relevant_cnt / search_cnt\n",
    "\n",
    "    return sum / len(relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "TfcXuKA3NyZ8"
   },
   "outputs": [],
   "source": [
    "def err(results, relevant_docs):\n",
    "    \"\"\"\n",
    "        Compute the expected reciprocal rank.\n",
    "        Input: \n",
    "            results: A sorted list of 2-tuples (document_id, score), with the most \n",
    "                    relevant document in the first position\n",
    "            relevant_docs: A set of relevant documents. \n",
    "        Output: ERR\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    err_score = 0\n",
    "    r_prod = 1\n",
    "\n",
    "    for i, (doc_id, _) in enumerate(results):\n",
    "      if doc_id in relevant_docs:\n",
    "        err_score += 1/(i+1) * r_prod * 0.5\n",
    "        r_prod *= 1 - 0.5\n",
    "    \n",
    "    return err_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "6OP_M-QhNyZ9"
   },
   "outputs": [],
   "source": [
    "#### metrics@k functions\n",
    "\n",
    "recall_at_1 = partial(recall_k, k=1)\n",
    "recall_at_5 = partial(recall_k, k=5)\n",
    "recall_at_10 = partial(recall_k, k=10)\n",
    "precision_at_1 = partial(precision_k, k=1)\n",
    "precision_at_5 = partial(precision_k, k=5)\n",
    "precision_at_10 = partial(precision_k, k=10)\n",
    "\n",
    "list_of_metrics = [\n",
    "    (\"ERR\", err),\n",
    "    (\"MAP\", average_precision),\n",
    "    (\"Recall@1\",recall_at_1),\n",
    "    (\"Recall@5\", recall_at_5),\n",
    "    (\"Recall@10\", recall_at_10),\n",
    "    (\"Precision@1\", precision_at_1),\n",
    "    (\"Precision@5\", precision_at_5),\n",
    "    (\"Precision@10\", precision_at_10)]\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "7hL0ypKWNyZ9"
   },
   "outputs": [],
   "source": [
    "#### Evaluate a search function\n",
    "\n",
    "list_of_search_fns = [\n",
    "    (\"BOW\", bow_search),\n",
    "    (\"TF-IDF\", tfidf_search),\n",
    "    (\"NaiveQL\", naive_ql_search),\n",
    "    (\"QL\", ql_search),\n",
    "    (\"BM25\", bm25_search)\n",
    "]\n",
    "\n",
    "def evaluate_search_fn(search_fn, metric_fns, index_set=None):\n",
    "    # build a dict query_id -> query \n",
    "    queries_by_id = dict((q[0], q[1]) for q in queries)\n",
    "    \n",
    "    metrics = {}\n",
    "    for metric, metric_fn in metric_fns:\n",
    "        metrics[metric] = np.zeros(len(qrels), dtype=np.float32)\n",
    "    \n",
    "    for i, (query_id, relevant_docs) in enumerate(qrels.items()):\n",
    "        query = queries_by_id[query_id]\n",
    "        if index_set:\n",
    "            results = search_fn(query, index_set)\n",
    "        else:\n",
    "            results = search_fn(query)\n",
    "        \n",
    "        for metric, metric_fn in metric_fns:\n",
    "            metrics[metric][i] = metric_fn(results, relevant_docs)\n",
    "\n",
    "    \n",
    "    \n",
    "    final_dict = {}\n",
    "    for metric, metric_vals in metrics.items():\n",
    "        final_dict[metric] = metric_vals.mean()\n",
    "    \n",
    "    return final_dict\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "12341234_12341234_12341234.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01458fb095424240baee28c6b347555c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_33dc764cdf144f79bd8d3ef202ff79bd",
      "placeholder": "​",
      "style": "IPY_MODEL_ac7ec29c04f64e2f962476650c3c4e68",
      "value": ""
     }
    },
    "1dc9aeec9c4e41bcb352d45e945489cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33dc764cdf144f79bd8d3ef202ff79bd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341aa53de823428d86fcb23b8fcfa9a9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ec6170bbcae48dc8c41adba6f85f5da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56084253838740e2b8c958a439e997c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_4ec6170bbcae48dc8c41adba6f85f5da",
      "placeholder": "​",
      "style": "IPY_MODEL_5a95c4a6dbe24f91b2c5b7a65376b590",
      "value": ""
     }
    },
    "5a95c4a6dbe24f91b2c5b7a65376b590": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ba4d8180cf1497d8978117ac7322416": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_73825775b25443b0bcab415fd3fcf5aa",
      "placeholder": "​",
      "style": "IPY_MODEL_e9537ba0a1184f7882569dd56d62558a",
      "value": ""
     }
    },
    "65273a2b291a4fbd83e1c4e49b69c6ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d9e360a58de04912b700c6d3db9eb043",
      "placeholder": "​",
      "style": "IPY_MODEL_e303d1549f674c03905a4cc1dd8d5de9",
      "value": ""
     }
    },
    "6f4ba93864434d0c84f6c3852f416564": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73825775b25443b0bcab415fd3fcf5aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d77db91787642c1885883b271e87e8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_341aa53de823428d86fcb23b8fcfa9a9",
      "placeholder": "​",
      "style": "IPY_MODEL_1dc9aeec9c4e41bcb352d45e945489cc",
      "value": ""
     }
    },
    "a479afdff19e4f35be231aa9a3bc736c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Search Bar",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_6f4ba93864434d0c84f6c3852f416564",
      "placeholder": "​",
      "style": "IPY_MODEL_dd1b24f4e41d42b3890c0612460caeb8",
      "value": ""
     }
    },
    "ac7ec29c04f64e2f962476650c3c4e68": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9e360a58de04912b700c6d3db9eb043": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd1b24f4e41d42b3890c0612460caeb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e303d1549f674c03905a4cc1dd8d5de9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9537ba0a1184f7882569dd56d62558a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
